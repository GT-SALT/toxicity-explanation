{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMyBpoyhFRGmDKn+tghgbut"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"czAEG95fIbyl"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# cd into project directory\n","%cd /content/drive/My\\ Drive/Georgia_Tech/Spring_2021/sbic_stereotypes/baselines"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2hjQ89cIJ4a"},"source":["!pip install transformers\n","!pip install datasets\n","!pip install rouge\n","!pip install bert_score\n","!pip install tqdm\n","\n","import torch\n","import pandas as pd\n","import numpy as np\n","\n","from training_utils import *\n","from datasets import Dataset\n","from transformers import AutoModelForCausalLM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9Hgi1FqJ8Oi"},"source":["DATA_DIR = '../data/'\n","MAX_LENGTH = 128\n","\n","#################### PICK MODEL AND DATASET ####################\n","from_file = DATA_DIR + 'SBIC.v2.dev.csv'\n","pred_col = ['HITId', 'post', 'sexYN', 'offensiveYN', 'intentYN', 'whoTarget', \\\n","            'targetMinority','targetStereotype', 'speakerMinorityYN']\n","\n","test_gpt_5epoch = {\n","                    'TO ACTUAL': 'pred/test/gpt_5epoch_dev_actual_sub.csv',\n","                    'TO PRED': 'pred/test/gpt_5epoch_dev_pred_sub.csv',\n","                    'TRAINED MODEL': 'model/gpt_5epoch/checkpoint-44734/',\n","                    'BASE MODEL': 'openai-gpt',\n","                    'SAMPLE SIZE': 2500\n","                  }\n","\n","test_gpt2_5epoch = {\n","                    'TO ACTUAL': 'pred/test/gpt2_5epoch_dev_actual.csv',\n","                    'TO PRED': 'pred/test/gpt2_5epoch_dev_pred.csv',\n","                    'TRAINED MODEL': 'model/gpt2_5epoch/checkpoint-48150/',\n","                    'BASE MODEL': 'gpt2',\n","                    'SAMPLE SIZE': 2500\n","                  }\n","\n","active_test = test_gpt_5epoch\n","################################################################\n","df = pd.read_csv(from_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bk2M_Hf_KGS1"},"source":["from testing_utils import *\n","\n","clean_post(df)\n","tokenizer = setup_tokenizer(active_test['BASE MODEL'])\n","model = AutoModelForCausalLM.from_pretrained(active_test['TRAINED MODEL'], \\\n","                                             pad_token_id=tokenizer.eos_token_id)\n","model.eval()\n","\n","def get_samples_from_actual(df, pred_col, active_test):\n","  #actual = df[df.HITId.isin(post_ids)]\n","  actual = df[pred_col].sample(n=active_test['SAMPLE SIZE'])\n","  actual = actual[pred_col]\n","  categorize_var(actual)\n","  return actual\n","\n","#post_ids = ['3W0XM68YZPPSXA20A826L4NZQHXK11','3IYI9285WSUH9T6G8KRE1L6DHMOCJG',\n","#            '3ZXV7Q5FJBI14RKKPU0TMNELOFTCFZ','3X55NP42EOAPI4DVA4LX5EOVK7XP39',\n","#            '33IXYHIZB5CW0VSMXQRHSSKZYQFE2S']\n","actual = get_samples_from_actual(df, pred_col, active_test)\n","predict_samples(model, tokenizer, actual, pred_col, active_test, MAX_LENGTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_dpjrhmQNKY"},"source":["## F1 and Precision/Recall Scores ##\n","from training_utils import *\n","from testing_utils import *\n","\n","actual = pd.read_csv(active_test['TO ACTUAL'])\n","pred = pd.read_csv(active_test['TO PRED'])\n","\n","print(\"Category: (Precision, Recall, F1)\")\n","print('Offensive: ', f1_score(actual, pred, 'offensiveYN', OFFY, OFFN))\n","print('Intent: ', f1_score(actual, pred, 'intentYN', INTY, INTN))\n","print('Lewd: ', f1_score(actual, pred, 'sexYN', LEWDY, LEWDN))\n","print('Group Targeted: ', f1_score(actual, pred, 'whoTarget', GRPY, GRPN))\n","print('In Group: ', f1_score(actual, pred, 'speakerMinorityYN', INGY, INGN))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5toSFKeGP4Re"},"source":["## BLEU/Rouge-L Scores ##\n","from testing_utils import *\n","from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n","from rouge import Rouge\n","\n","keep_col = ['HITId', 'post', 'sexYN', 'offensiveYN', 'intentYN', 'whoTarget', \\\n","            'speakerMinorityYN']\n","\n","sub_df = df[['HITId', 'targetMinority', 'targetStereotype']]\n","sub_df = aggregate_and_format(sub_df)\n","actual = actual[keep_col].join(sub_df, on='HITId').reindex(columns=pred_col)\n","\n","references_tm, hypotheses_tm = get_references_and_hypotheses('targetMinority', actual, pred)\n","bleu_score_tm_max, bleu_score_tm_avg = get_bleu_score(references_tm, hypotheses_tm)\n","rouge_scores_tm_max, rouge_scores_tm_avg = get_rouge_scores(references_tm, hypotheses_tm)\n","\n","references_ts, hypotheses_ts = get_references_and_hypotheses('targetStereotype', actual, pred)\n","bleu_score_ts_max, bleu_score_ts_avg = get_bleu_score(references_ts, hypotheses_ts)\n","rouge_scores_ts_max, rouge_scores_ts_avg = get_rouge_scores(references_ts, hypotheses_ts)\n","\n","print(\"Target Minority Scores: \")\n","print(\"Bleu Score (Avg): \", bleu_score_tm_avg)\n","print(\"Bleu Score (Max): \", bleu_score_tm_max)\n","print(\"Rouge Score (Avg) (Precision, Recall, F1): \", rouge_scores_tm_avg)\n","print(\"Rouge Score (Max) (Precision, Recall, F1): \", rouge_scores_tm_max)\n","\n","print(\"Implied Stereotype Scores: \")\n","print(\"Bleu Score (Avg): \", bleu_score_ts_avg)\n","print(\"Bleu Score (Max): \", bleu_score_ts_max)\n","print(\"Rouge Score (Avg) (Precision, Recall, F1): \", rouge_scores_ts_avg)\n","print(\"Rouge Score (Max) (Precision, Recall, F1): \", rouge_scores_ts_max)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eg6khVehZXHb"},"source":["from datasets import load_metric\n","from testing_utils import *\n","\n","metric = load_metric('bertscore')\n","bert_scores_ts = metric.compute(predictions=hypotheses_ts, references=references_ts, lang='en')\n","bert_scores_tm = metric.compute(predictions=hypotheses_tm, references=references_tm, lang='en')\n","\n","bert_score_ts = get_bert_score(bert_scores_ts, hypotheses_ts, references_ts)\n","bert_score_tm = get_bert_score(bert_scores_tm, hypotheses_tm, references_tm)\n","\n","print('Target Minority Scores')\n","print('BERT Score (Max) (Precision, Recall, F1): ', bert_score_tm)\n","print('Implied Stereotype Scores')\n","print('BERT Score (Max) (Precision, Recall, F1): ', bert_score_ts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dT8AdQ5_VOtv"},"source":[""],"execution_count":null,"outputs":[]}]}