{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM5ZXE1oJstBDs9SgI3SJpq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TaQvM6nUfFKv"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# cd into project directory\n","%cd /content/drive/My\\ Drive/Georgia_Tech/Spring_2021/sbic_stereotypes/src/classification"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RoxnWo6foNJ"},"source":["!pip install transformers\n","!pip install datasets\n","\n","import torch\n","import pandas as pd\n","import numpy as np\n","\n","############## MODIFY THESE PARAMS ##############\n","CLASSIFY_COL = 'whoTarget'\n","MODEL_NAME = 'model/' + CLASSIFY_COL + '/checkpoint-1280/'\n","#################################################\n","\n","DATA_DIR = '../../data/'\n","BASE_MODEL = 'bert-base-uncased'\n","CLEAN_DATA_FILE = 'data/train_' + CLASSIFY_COL + '.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dapCNVFBhE0l"},"source":["from classifier_utils import *\n","\n","# Classify column\n","df = pd.read_csv(DATA_DIR + 'SBIC.v2.dev.csv')\n","df = prep_df_for_classification(df, CLEAN_DATA_FILE, CLASSIFY_COL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9fbZq4Wq0PP"},"source":["from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","from tqdm import tqdm\n","import math\n","\n","tokenizer = BertTokenizer.from_pretrained(BASE_MODEL)\n","model = BertForSequenceClassification.from_pretrained(MODEL_NAME)\n","model.eval()\n","\n","num_examples = df.shape[0]\n","outputs = np.empty((num_examples, 2))\n","\n","for i in tqdm(range(num_examples)):  \n","  inputs = tokenizer(df[\"post\"][i], return_tensors='pt')\n","  output = model(**inputs)\n","  outputs[i] = output['logits'].detach().cpu().numpy()\n","\n","np.savetxt('pred/' + CLASSIFY_COL + '_predictions.csv', outputs)\n","np.savetxt('pred/' + CLASSIFY_COL + '_labels.csv', df[CLASSIFY_COL].to_numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UqY5NDCc2Qb0"},"source":["y_hat = np.loadtxt('pred/' + CLASSIFY_COL + \"_predictions.csv\")\n","y = np.loadtxt('pred/' + CLASSIFY_COL + '_labels.csv')\n","\n","y_hat = np.exp(y_hat) / np.sum(np.exp(y_hat), axis=1)[:,None]\n","y_hat = np.argmax(y_hat, axis=1)\n","\n","tp = np.sum((y_hat == 1) & (y == 1))\n","fp = np.sum((y_hat == 1) & (y == 0))\n","tn = np.sum((y_hat == 0) & (y == 0))\n","fn = np.sum((y_hat == 0) & (y == 1))\n","\n","print(\"tp: \", tp)\n","print(\"fp: \", fp)\n","print(\"tn: \", tn)\n","print(\"fn: \", fn)\n","\n","precision = float(tp) / (tp + fp)\n","recall = float(tp) / (tp + fn)\n","f1 = 2 * ((precision * recall) / (precision + recall))\n","\n","print(\"precision: \", precision)\n","print(\"recall: \", recall)\n","print(\"f1: \", f1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t6wNs1Qa2a7_"},"source":[""],"execution_count":null,"outputs":[]}]}