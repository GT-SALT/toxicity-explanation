{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_seq2seq.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPd7gj3uezxu8y6vphIDxCs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ZiPJTDAQgzFZ"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# cd into project directory\n","%cd /content/drive/My\\ Drive/Georgia_Tech/Spring_2021/sbic_stereotypes/src"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yUfAz78g9L2"},"source":["!pip install transformers\n","!pip install datasets\n","\n","import torch\n","import pandas as pd\n","import numpy as np\n","\n","# Useful constants\n","CLASSIFIER_MODEL_NAME = 'bert-base-uncased'\n","CLASSIFIERS = ['./classification/model/whoTarget/checkpoint-1280/']\n","\n","#CLASSIFIERS = ['./classification/model/offensiveYN/checkpoint-898/',\n","#               './classification/model/intentYN/checkpoint-898/',\n","#               './classification/model/sexYN/checkpoint-898/',\n","#               './classification/model/whoTarget/checkpoint-1280/']\n","\n","SEQ2SEQ_MODEL_NAME = 'facebook/bart-base'\n","SEQ2SEQ_MODEL = 'model/checkpoint-10782/'\n","DATA_DIR = '../data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8rDu--bDlpnD"},"source":["from seq2seq_utils import *\n","from torch import nn, torch\n","from datasets import Dataset\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import BartTokenizer, BartForConditionalGeneration\n","\n","df = pd.read_csv(DATA_DIR + 'SBIC.v2.dev.csv')\n","clean_post(df)\n","df = clean_target(df)\n","df.to_csv('data/clean_dev_df.csv')\n","\n","dataset = Dataset.from_pandas(df)\n","seq2seq_tok, classifier_tok, tokenized = get_tokenized_data(\n","    dataset,\n","    SEQ2SEQ_MODEL_NAME,\n","    CLASSIFIER_MODEL_NAME\n",")\n","\n","print(tokenized)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zR7L-iaDkJzd"},"source":["from transformers import BartForConditionalGeneration\n","from seq2seq import BartForConditionalGenerationJoinModel\n","import torch\n","\n","### MODEL START CODE ###\n","\n","### MODEL END CODE ###\n","model = BartForConditionalGenerationJoinModel.from_pretrained(\n","            SEQ2SEQ_MODEL_NAME,\n","            classifiers=CLASSIFIERS,\n","        )\n","model.eval();"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gt9w-f-gWG61"},"source":["i = 345\n","j = 350\n","\n","#input_ids = torch.tensor([tokenized['input_ids'][i]])\n","#attention_mask = torch.tensor([tokenized['attention_mask'][i]])\n","#classifier_inputs = torch.tensor([tokenized['classifier_inputs'][i]])\n","#classifier_attention = torch.tensor([tokenized['classifier_attention'][i]])\n","\n","input_ids = torch.tensor(tokenized['input_ids'][i:j])\n","attention_mask = torch.tensor(tokenized['attention_mask'][i:j])\n","classifier_inputs = torch.tensor(tokenized['classifier_inputs'][i:j])\n","classifier_attention = torch.tensor(tokenized['classifier_attention'][i:j])\n","num_beams = 10\n","\n","encoder_outputs = model.get_encoder()(\n","    input_ids,\n","    attention_mask,\n","    return_dict=True,\n",")\n","\n","kwargs = {\n","    'attention_mask':attention_mask,\n","    'classifier_inputs': classifier_inputs,\n","    'classifier_attention': classifier_attention,\n","    'beam_search': num_beams > 1,\n","    'encoder_outputs': encoder_outputs,\n","}\n","\n","#for i in range(5):\n","#  model(input_ids=input_ids, attention_mask=attention_mask, classifier_inputs=classifier_inputs, classifier_attention=classifier_attention);\n","outputs = model.generate(input_ids, num_beams=num_beams, **kwargs)\n","seq2seq_tok.decode(outputs[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFtkWC_DsUTv"},"source":[""],"execution_count":null,"outputs":[]}]}