{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO6qiLOXGuOnIDGGGhvXevx"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"czAEG95fIbyl"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# cd into project directory\n","%cd /content/drive/My\\ Drive/Georgia_Tech/Spring_2021/sbic_stereotypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2hjQ89cIJ4a"},"source":["!pip install transformers\n","!pip install datasets\n","!pip install rouge-score\n","\n","import torch\n","import pandas as pd\n","import numpy as np\n","\n","from data_preprocessing import *\n","from datasets import Dataset\n","from transformers import AutoModelForCausalLM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9Hgi1FqJ8Oi"},"source":["#################### PICK MODEL AND DATASET ####################\n","from_file = 'data/SBIC.v2.dev.csv'\n","pred_col = ['HITId', 'post', 'sexYN', 'offensiveYN', 'intentYN', 'whoTarget', \\\n","            'targetMinority','targetStereotype', 'speakerMinorityYN']\n","\n","test_gpt_5epoch = {\n","                    'TO ACTUAL': 'data/test/sample_gpt_5epoch_dev_actual.csv',\n","                    'TO PRED': 'data/test/sample_gpt_5epoch_dev_pred.csv',\n","                    'TRAINED MODEL': 'model/gpt_5epoch/checkpoint-44734/',\n","                    'BASE MODEL': 'openai-gpt',\n","                    'SAMPLE SIZE': 2500\n","                  }\n","\n","test_gpt2_5epoch = {\n","                    'TO ACTUAL': 'data/test/sample_gpt2_5epoch_dev_actual.csv',\n","                    'TO PRED': 'data/test/sample_gpt2_5epoch_dev_pred.csv',\n","                    'TRAINED MODEL': 'model/gpt2_5epoch/checkpoint-48150/',\n","                    'BASE MODEL': 'gpt2',\n","                    'SAMPLE SIZE': 2500\n","                  }\n","\n","active_test = test_gpt_5epoch\n","################################################################\n","df = pd.read_csv(from_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bk2M_Hf_KGS1"},"source":["\"\"\"\n","from testing_utils import *\n","\n","clean_post(df)\n","tokenizer = setup_tokenizer(active_test['BASE MODEL'])\n","model = AutoModelForCausalLM.from_pretrained(active_test['TRAINED MODEL'], \\\n","                                             pad_token_id=tokenizer.eos_token_id)\n","model.eval()\n","\n","def get_samples_from_actual(df, pred_col, active_test):\n","  actual = df[pred_col].sample(n=active_test['SAMPLE SIZE'])\n","  categorize_var(actual)\n","  return actual\n","\n","actual = get_samples_from_actual(df, pred_col, active_test)\n","predict_samples(model, tokenizer, actual, pred_col, active_test)\n","\"\"\";"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_dpjrhmQNKY"},"source":["## F1 and Precision/Recall Scores ##\n","from data_preprocessing import *\n","from testing_utils import *\n","\n","actual = pd.read_csv(active_test['TO ACTUAL'])\n","pred = pd.read_csv(active_test['TO PRED'])\n","\n","print(\"Category: (Precision, Recall, F1)\")\n","print('Offensive: ', f1_score(actual, pred, 'offensiveYN', OFFY, OFFN))\n","print('Intent: ', f1_score(actual, pred, 'intentYN', INTY, INTN))\n","print('Lewd: ', f1_score(actual, pred, 'sexYN', LEWDY, LEWDN))\n","print('Group Targeted: ', f1_score(actual, pred, 'whoTarget', GRPY, GRPN))\n","print('In Group: ', f1_score(actual, pred, 'speakerMinorityYN', INGY, INGN))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5toSFKeGP4Re"},"source":["## BLEU/Rouge-L Scores ##\n","from testing_utils import *\n","\n","keep_col = ['HITId', 'post', 'sexYN', 'offensiveYN', 'intentYN', 'whoTarget', \\\n","            'speakerMinorityYN']\n","\n","sub_df = df[['HITId', 'targetMinority', 'targetStereotype']]\n","sub_df = aggregate_and_format(sub_df)\n","actual = actual[keep_col].join(sub_df, on='HITId').reindex(columns=pred_col)\n","\n","references_tm, hypotheses_tm = get_references_and_hypotheses('targetMinority', actual, pred)\n","bleu_score_tm = get_bleu_score(references_tm, hypotheses_tm)\n","rouge_scores_tm = get_rouge_scores(references_tm, hypotheses_tm)\n","\n","references_ts, hypotheses_ts = get_references_and_hypotheses('targetStereotype', actual, pred)\n","bleu_score_ts = get_bleu_score(references_ts, hypotheses_ts)\n","rouge_scores_ts = get_rouge_scores(references_ts, hypotheses_ts)\n","\n","print(\"Target Minority Scores: \")\n","print(\"Bleu Score: \", bleu_score_tm)\n","print(\"Rouge Score (Precision, Recall, F1): \", rouge_scores_tm)\n","\n","print(\"Implied Stereotype Scores: \")\n","print(\"Bleu Score: \", bleu_score_ts)\n","print(\"Rouge Score (Precision, Recall, F1): \", rouge_scores_ts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eg6khVehZXHb"},"source":["total_posts = actual.shape[0]\n","off_pos = actual[actual['offensiveYN'] == OFFY].shape[0]\n","int_pos = actual[actual['intentYN'] == INTY].shape[0]\n","lewd_pos = actual[actual['sexYN'] == LEWDY].shape[0]\n","grp_pos = actual[actual['whoTarget'] == GRPY].shape[0]\n","ing_pos = actual[actual['speakerMinorityYN'] == INGY].shape[0]\n","\n","print(\"Offensiveness Skew: \", off_pos / total_posts)\n","print(\"Intent Skew: \", int_pos / total_posts)\n","print(\"Lewdness Skew: \", lewd_pos / total_posts)\n","print(\"Group Targeted Skew: \", grp_pos / total_posts)\n","print(\"In Group Skew: \", ing_pos / total_posts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dT8AdQ5_VOtv"},"source":[""],"execution_count":null,"outputs":[]}]}