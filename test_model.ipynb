{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPFDUce2uBgED9tawOkNZDZ"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"czAEG95fIbyl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614359594723,"user_tz":480,"elapsed":19297,"user":{"displayName":"Rohit Sridhar","photoUrl":"","userId":"02475871793271357019"}},"outputId":"ba15e339-fcc1-4ee0-a201-ce410f9354d7"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# cd into project directory\n","%cd /content/drive/My\\ Drive/Georgia_Tech/Spring_2021/sbic_stereotypes"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1M873oJOlIb1Bd5vliq6d04b61XsHLT5h/sbic_stereotypes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l2hjQ89cIJ4a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614359687049,"user_tz":480,"elapsed":27159,"user":{"displayName":"Rohit Sridhar","photoUrl":"","userId":"02475871793271357019"}},"outputId":"c8439282-c4e9-4bd3-90c1-cba8ec7bc833"},"source":["!pip install rouge\n","!pip install transformers\n","!pip install datasets\n","\n","import torch\n","import pandas as pd\n","import numpy as np\n","\n","from data_preprocessing import *\n","from datasets import Dataset\n","from transformers import AutoModelForCausalLM"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting rouge\n","  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.0\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 37.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 22.6MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=0dcc6687dcb666f80343c0861370e9df06834fbe958c3f06c715a146eefbbb2c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n","Collecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/12/5fd53adc5ba8a8d562b19f2c1c859547659e96b87a767cd52556538d205e/datasets-1.3.0-py3-none-any.whl (181kB)\n","\u001b[K     |████████████████████████████████| 184kB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting huggingface-hub==0.0.2\n","  Downloading https://files.pythonhosted.org/packages/b5/93/7cb0755c62c36cdadc70c79a95681df685b52cbaf76c724facb6ecac3272/huggingface_hub-0.0.2-py3-none-any.whl\n","Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n","Collecting pyarrow>=0.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/61/814f4c8d2cd4d51dfd80a9c4ea14b8fd09e37cb0f6962c1f04d504a02e03/pyarrow-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (20.7MB)\n","\u001b[K     |████████████████████████████████| 20.7MB 34.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting fsspec\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 44.8MB/s \n","\u001b[?25hCollecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 41.9MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets) (3.0.12)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: huggingface-hub, pyarrow, fsspec, xxhash, datasets\n","  Found existing installation: pyarrow 0.14.1\n","    Uninstalling pyarrow-0.14.1:\n","      Successfully uninstalled pyarrow-0.14.1\n","Successfully installed datasets-1.3.0 fsspec-0.8.7 huggingface-hub-0.0.2 pyarrow-3.0.0 xxhash-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R9Hgi1FqJ8Oi","executionInfo":{"status":"ok","timestamp":1614364683610,"user_tz":480,"elapsed":16377,"user":{"displayName":"Rohit Sridhar","photoUrl":"","userId":"02475871793271357019"}}},"source":["#################### PICK MODEL AND DATASET ####################\n","from_file = 'data/SBIC.v2.dev.csv'\n","\n","test_gpt_5epoch = {\n","                    'TO ACTUAL': 'data/test/sample_gpt_5epoch_dev_actual.csv',\n","                    'TO PRED': 'data/test/sample_gpt_5epoch_dev_pred.csv',\n","                    'TRAINED MODEL': 'model/gpt_5epoch/checkpoint-42500/',\n","                    'BASE MODEL': 'openai-gpt',\n","                    'SAMPLE SIZE': 5000\n","                  }\n","\n","test_gpt2_5epoch = {\n","                    'TO ACTUAL': 'data/test/sample_gpt2_5epoch_dev_actual.csv',\n","                    'TO PRED': 'data/test/sample_gpt2_5epoch_dev_pred.csv',\n","                    'TRAINED MODEL': 'model/gpt2_5epoch/checkpoint-47334/',\n","                    'BASE MODEL': 'gpt2',\n","                    'SAMPLE SIZE': 5000\n","                  }\n","\n","test_lb_gpt2_5epoch = {\n","                    'TO ACTUAL': 'data/test/sample_lb_gpt2_5epoch_dev_actual.csv',\n","                    'TO PRED': 'data/test/sample_lb_gpt2_5epoch_dev_pred.csv',\n","                    'TRAINED MODEL': 'model/gpt2_5epoch/checkpoint-47334/',\n","                    'BASE MODEL': 'gpt2',\n","                    'SAMPLE SIZE': 1000\n","                  }\n","\n","active_test = test_gpt2_5epoch\n","################################################################\n","\n","tokenizer = setup_tokenizer(active_test['BASE MODEL'])\n","model = AutoModelForCausalLM.from_pretrained(active_test['TRAINED MODEL'], \\\n","                                             pad_token_id=tokenizer.eos_token_id)\n","model.eval()\n","df = pd.read_csv(from_file)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"bk2M_Hf_KGS1"},"source":["from testing_utils import *\n","\n","pred_col = ['post', 'sexYN', 'offensiveYN', 'intentYN', 'whoTarget', 'targetMinority','targetStereotype', 'speakerMinorityYN']\n","clean_post(df)\n","\n","def get_samples_from_actual(df, pred_col, active_test):\n","  actual = df[pred_col].sample(n=active_test['SAMPLE SIZE'])\n","  categorize_var(actual)\n","  return actual\n","\n","def get_lewd_balanced_samples_from_actual(df, pred_col, active_test):\n","  actual = df[pred_col].copy()\n","  categorize_var(actual)\n","  half_sample = int(active_test['SAMPLE SIZE'] / 2)\n","\n","  actual_1 = actual.loc[actual['sexYN'] == LEWDY]\n","  actual_2 = actual.loc[actual['sexYN'] == LEWDN]\n","\n","  actual = pd.concat([actual_1.sample(n=half_sample), actual_2.sample(n=half_sample)], axis=0)\n","  return actual\n","\n","actual = get_lewd_balanced_samples_from_actual(df, pred_col, active_test)\n","predict_samples(model, tokenizer, actual, pred_col, active_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_dpjrhmQNKY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614364687027,"user_tz":480,"elapsed":311,"user":{"displayName":"Rohit Sridhar","photoUrl":"","userId":"02475871793271357019"}},"outputId":"1e39441f-926e-4e8d-967d-9e5707a097be"},"source":["## F1 and Precision/Recall Scores ##\n","\n","from data_preprocessing import *\n","from testing_utils import *\n","\n","actual = pd.read_csv(active_test['TO ACTUAL'])\n","pred = pd.read_csv(active_test['TO PRED'])\n","\n","print(\"Category: (F1, Precision, Recall)\")\n","print('Offensive: ', f1_score(actual, pred, 'offensiveYN', OFFY, OFFN))\n","print('Intent: ', f1_score(actual, pred, 'intentYN', INTY, INTN))\n","print('Lewd: ', f1_score(actual, pred, 'sexYN', LEWDY, LEWDN))\n","print('Group Targeted: ', f1_score(actual, pred, 'whoTarget', GRPY, GRPN))\n","print('In Group: ', f1_score(actual, pred, 'speakerMinorityYN', INGY, INGN))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Category: (F1, Precision, Recall)\n","Offensive:  (0.8667888787045523, 0.8154642138545559, 0.9250081512879035)\n","Intent:  (0.8396584440227703, 0.7631503305547571, 0.9332161687170475)\n","Lewd:  (0.4379310344827586, 0.675531914893617, 0.3239795918367347)\n","Group Targeted:  (0.7930611529700367, 0.6709160984286985, 0.9695801199657241)\n","In Group:  (0, 0, 0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5toSFKeGP4Re","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614362608300,"user_tz":480,"elapsed":9536,"user":{"displayName":"Rohit Sridhar","photoUrl":"","userId":"02475871793271357019"}},"outputId":"6375d9b0-4377-4732-92b4-1d54bfa0af98"},"source":["## BLEU/Rouge-L Scores ##\n","from nltk.translate.bleu_score import corpus_bleu\n","from rouge import Rouge\n","\n","def print_scores(col_name):\n","  cmp_grp_target = pd.concat([actual[col_name].rename('actual'), \\\n","                              pred[col_name].rename('pred')], \\\n","                              axis=1)\n","  cmp_grp_target = cmp_grp_target.replace(np.nan, '', regex=True)\n","  cmp_grp_target = cmp_grp_target[cmp_grp_target['actual'] != '']\n","\n","  cmp_grp_target['actual'] = cmp_grp_target['actual'].str.lower()\n","  cmp_grp_target['pred'] = cmp_grp_target['pred'].str.lower()\n","\n","  references = cmp_grp_target.actual.tolist()\n","  hypotheses = cmp_grp_target.pred.tolist()\n","\n","  rouge = Rouge()\n","  scores = rouge.get_scores(hypotheses, references, avg=True, ignore_empty=True)\n","  print('Rouge-L: ', scores['rouge-l'])\n","\n","  references = [[reference] for reference in references]\n","  print('Bleu: ', corpus_bleu(references, hypotheses, weights=[0.5,0.5,0,0]))\n","\n","print('Scores for Target Minority')\n","print_scores('targetMinority')\n","\n","print('Scores for Target Stereotype')\n","print_scores('targetStereotype')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Scores for Target Minority\n","Rouge-L:  {'f': 0.4633071314541108, 'p': 0.47273462783171527, 'r': 0.46058901454532514}\n","Bleu:  0.39285895624340844\n","Scores for Target Stereotype\n","Rouge-L:  {'f': 0.3215983915249947, 'p': 0.34539919450367207, 'r': 0.3168531116983972}\n","Bleu:  0.37323984063358867\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eg6khVehZXHb"},"source":[""],"execution_count":null,"outputs":[]}]}